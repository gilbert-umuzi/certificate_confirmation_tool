{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3556154",
      "metadata": {
        "id": "d3556154"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "\n",
        "# For Python packages\n",
        "!pip install --upgrade PyPDF2\n",
        "!pip install --upgrade pdf2image\n",
        "!pip install --upgrade pdfplumber\n",
        "!pip install --upgrade pytesseract\n",
        "!pip install --upgrade fuzzywuzzy\n",
        "\n",
        "!pip install python-Levenshtein\n",
        "!pip install pandas\n",
        "!pip install scikit-image\n",
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "\n",
        "pip install matplotlib\n",
        "pip install seaborn\n",
        "\n",
        "# Run in terminal\n",
        "# brew install poppler\n",
        "# brew install tesseract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324d4bac",
      "metadata": {
        "id": "324d4bac"
      },
      "outputs": [],
      "source": [
        "# Import statements\n",
        "import os\n",
        "import pandas as pd\n",
        "import re  # For regular expressions\n",
        "from PIL import Image\n",
        "from PyPDF2 import PdfReader\n",
        "from PyPDF2 import PdfFileReader\n",
        "from pdf2image import convert_from_path\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "import requests  # For downloading files\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "from fuzzywuzzy import fuzz  # for text similarity\n",
        "import json\n",
        "from ast import literal_eval\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f6fd1a",
      "metadata": {
        "id": "a0f6fd1a"
      },
      "outputs": [],
      "source": [
        "# File types that are supported\n",
        "SUPPORTED_EXTENSIONS = ['.pdf', '.png', '.jpg', '.jpeg', '.bmp', '.tiff']\n",
        "\n",
        "# Names of the courses / certificates that are being evaluated\n",
        "certificate_names = [\n",
        "    'Boost Your Career with SAP Skills My Learning screenshot',\n",
        "    'Learn how to learn (Google)',\n",
        "    'Business Communication (Google)',\n",
        "    'Communicate your ideas through storytelling and design (Google)',\n",
        "    'Get started with Microsoft Teams',\n",
        "    'Tech for Good: The Role of ICT in Achieving the SDGs'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "172466f3",
      "metadata": {
        "id": "172466f3"
      },
      "outputs": [],
      "source": [
        "# When working in Colab, mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970b5f54",
      "metadata": {
        "id": "970b5f54"
      },
      "outputs": [],
      "source": [
        "# Define the directory where attachments are stored\n",
        "attachments_dir = '/Users/gilbert/Downloads/attachments '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ac373cd",
      "metadata": {
        "id": "1ac373cd"
      },
      "outputs": [],
      "source": [
        "# Sanitize filepath and check it (requires Helper Functions to be loaded)\n",
        "attachments_dir = sanitize_path(attachments_dir)\n",
        "\n",
        "# Check if attachments directory exists\n",
        "if check_file_exists(attachments_dir):\n",
        "    print(f\"The directory {attachments_dir} exists.\")\n",
        "\n",
        "    # Show the list of subfolders\n",
        "    with os.scandir(attachments_dir) as entries:\n",
        "        subfolders = [entry.name for entry in entries if entry.is_dir()]\n",
        "    print(f\"Subfolders: {subfolders}\")\n",
        "else:\n",
        "    print(f\"The directory {attachments_dir} does not exist. Please check the path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "922ded21",
      "metadata": {
        "id": "922ded21"
      },
      "outputs": [],
      "source": [
        "# Load template certificates into their respective folders\n",
        "\n",
        "# Define the folder paths for each certificate type\n",
        "certificate_folders = {\n",
        "    'Boost Your Career with SAP Skills My Learning screenshot': '/Users/gilbert/Downloads/example_certs/Boost Your Career with SAP Skills My Learning screenshot',\n",
        "    'Learn how to learn (Google)': '/Users/gilbert/Downloads/example_certs/Learn how to learn (Google)',\n",
        "    'Business Communication (Google)': '/Users/gilbert/Downloads/example_certs/Business Communication (Google)',\n",
        "    'Get started with Microsoft Teams': '/Users/gilbert/Downloads/example_certs/Get started with Microsoft Teams',\n",
        "    'Tech for Good: The Role of ICT in Achieving the SDGs': '/Users/gilbert/Downloads/example_certs/Tech for Good: The Role of ICT in Achieving the SDGs',\n",
        "    'Communicate your ideas through storytelling and design (Google)': '/Users/gilbert/Downloads/example_certs/Communicate your ideas through storytelling and design (Google)'\n",
        "    # ... (more certificates and their corresponding folders)\n",
        "}\n",
        "\n",
        "# Populate the cert_name_to_example_paths dictionary by listing all files in each folder\n",
        "cert_name_to_example_paths = {}\n",
        "for cert_name, folder_path in certificate_folders.items():\n",
        "    if os.path.exists(folder_path):\n",
        "        files_in_folder = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "        cert_name_to_example_paths[cert_name] = files_in_folder\n",
        "    else:\n",
        "        print(f\"Warning: The folder for '{cert_name}' does not exist at path:\\n\\t{folder_path}\")\n",
        "\n",
        "# Debug: Print to verify\n",
        "print(\"\\n--- Certificate Names and their Example Paths ---\")\n",
        "for cert_name, example_paths in cert_name_to_example_paths.items():\n",
        "    print(f\"\\nCertificate Name: {cert_name}\")\n",
        "    for path in example_paths:\n",
        "        print(f\"\\t- {path}\")\n",
        "\n",
        "# Check if all certificate folders have at least one file\n",
        "print(\"\\n--- Certificate Folders with Missing Example Files ---\")\n",
        "for cert_name, example_paths in cert_name_to_example_paths.items():\n",
        "    if not example_paths:\n",
        "        print(f\"Warning: No example files found for '{cert_name}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a9f861",
      "metadata": {
        "id": "c1a9f861"
      },
      "outputs": [],
      "source": [
        "# Download example_certs to have a record\n",
        "\n",
        "# Create a zip file from the folder\n",
        "shutil.make_archive('/content/example_certs', 'zip', '/content/example_certs')\n",
        "\n",
        "# Download the zip file\n",
        "files.download('/content/example_certs.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342def25",
      "metadata": {
        "id": "342def25"
      },
      "outputs": [],
      "source": [
        "# Extract text from example certificates to be used for comparrison\n",
        "\n",
        "# Initialize an empty dictionary to hold the extracted text for each example certificate\n",
        "example_cert_texts = {}\n",
        "\n",
        "# Loop through each certificate type and its corresponding example paths\n",
        "for cert_name, example_paths in cert_name_to_example_paths.items():\n",
        "    example_cert_texts[cert_name] = []\n",
        "    print(f\"Processing certificates of type: {cert_name}\")\n",
        "    print(\"=\" * 50)  # Print a separator line for readability\n",
        "\n",
        "    for example_path in example_paths:\n",
        "        try:\n",
        "            if os.path.exists(example_path):\n",
        "                extracted_text = extract_text_from_file(example_path)\n",
        "                example_cert_texts[cert_name].append(extracted_text)\n",
        "                print(f\"Successfully processed: {example_path}\")\n",
        "            else:\n",
        "                print(f\"\\nWarning: The example certificate file for {cert_name} is missing.\\nPath: {example_path}\\n\")\n",
        "                print(\"-\" * 50)  # Print a separator line for readability\n",
        "\n",
        "        except pytesseract.TesseractError as e:\n",
        "            print(f\"\\nError: An issue occurred while processing the file at {example_path}.\\nError Details: {e}\\n\")\n",
        "            print(\"-\" * 50)  # Print a separator line for readability\n",
        "\n",
        "    print(\"=\" * 50)  # Print a separator line for readability\n",
        "\n",
        "# The dictionary example_cert_texts will now hold the extracted text for each certificate that exists\n",
        "print(\"\\nFinal extracted text dictionary:\")\n",
        "\n",
        "for cert_type, extracted_texts in example_cert_texts.items():\n",
        "    print(f\"\\nCertificate Type: {cert_type}\")\n",
        "    print(\"-\" * 50)  # Separator\n",
        "\n",
        "    for i, text in enumerate(extracted_texts):\n",
        "        print(\"\\n\\tExample {}:\\n\\t-------------------\".format(i + 1))\n",
        "        print(\"\\t{}\".format(text.replace('\\n', '\\n\\t')))  # Replacing new lines within the text with new lines followed by tabs for better readability\n",
        "\n",
        "    print(\"=\" * 50)  # Separator\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd6ab1d",
      "metadata": {
        "id": "6fd6ab1d"
      },
      "outputs": [],
      "source": [
        "# Define key phrases to calculate the 'Text Similarity Score'\n",
        "\n",
        "# Dictionary to hold key phrases for each certificate type\n",
        "key_phrases_by_cert = {\n",
        "    'Business Communication (Google)': [\n",
        "        'Business Communication', 'Goodwill Community Foundation',\n",
        "        'Congratulations! You answered enough questions correctly',\n",
        "        'Correct Answers: 5/5', 'Total Points: 5/5','Google', 'Passed', 'Assessment Passed', '100%'\n",
        "    ],\n",
        "    'Boost Your Career with SAP Skills My Learning screenshot': [\n",
        "        'Date completed', 'Learning Journey', 'Completed', 'sap', 'SAP Learning Journey',\n",
        "        'Boost Your Career with SAP Skills', 'Available', \"Type Name Status Date completed\", \"Hi, Aliyu - welcome to My Learning\",\n",
        "        \"What's next\"\n",
        "    ],\n",
        "    'Learn how to learn (Google)': [\n",
        "        'Communicate Effectively at Work', 'HAS COMPLETED', 'THIS CERTIFIES THAT', 'AWARDED ON',\n",
        "        'Applied Digital Skills', 'date:', 'lesson:'\n",
        "    ],\n",
        "    'Communicate your ideas through storytelling and design (Google)': [\n",
        "        'Communicate your ideas', 'Storytelling', 'Design', 'Google','OpenClassrooms',\n",
        "        'Congratulations!','Assessment Passed', '4/4 Correct Answers', 'Total Points: 4/4'\n",
        "    ],\n",
        "    'Get started with Microsoft Teams': [\n",
        "        'Microsoft Teams', 'Facilitate meetings', 'and chats', 'through conversations in channels and chats',\n",
        "        'settings as a team owner in Microsoft Teams','Learn how to create teams and channels',\n",
        "        'Personalize your environment by managing your', 'Number of modules completed',\n",
        "        'collaborating with communicate and collaborate more effectively', 'using Outlook with Teams',\n",
        "        'Module title Description Completed Duration', 'Learn how to use Microsoft Teams to schedule'\n",
        "    ],\n",
        "    'Tech for Good: The Role of ICT in Achieving the SDGs': [\n",
        "        'Tech for Good', 'ICT', 'SDGs', 'Certificate', 'The Role of ICT in Achieving the SDGs',\n",
        "        'Course Progress Dates Discussion Overview About the Partners',\n",
        "        'This represents how much of the course content you have completed',\n",
        "        'You are in an audit track and do not qualify for a certificate', 'Earn a certificate', 'Upgrade now'\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458b1921",
      "metadata": {
        "id": "458b1921"
      },
      "outputs": [],
      "source": [
        "# Set CSV path\n",
        "\n",
        "# Define the file path\n",
        "file_path = '/Users/gilbert/Downloads/view_2.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7df88a",
      "metadata": {
        "id": "0b7df88a"
      },
      "outputs": [],
      "source": [
        "# Read the csv as a dataframe\n",
        "\n",
        "# Read the renamed CSV file into a DataFrame\n",
        "df_learners = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows to get an overview of the data\n",
        "df_learners.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2b569f9",
      "metadata": {
        "id": "f2b569f9"
      },
      "outputs": [],
      "source": [
        "df_learners.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8317831",
      "metadata": {
        "id": "f8317831"
      },
      "outputs": [],
      "source": [
        "# Get column names\n",
        "df_learners.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c470339",
      "metadata": {
        "id": "7c470339"
      },
      "outputs": [],
      "source": [
        "# Select relevant columns, including all certificates and screenshots, into a new data frame\n",
        "df_learners_selected = df_learners[['Learner ID',\n",
        "                                    'Email address',\n",
        "                                    'First Name',\n",
        "                                    'Last name',\n",
        "                                    'Block 1 progress %',\n",
        "                                    'Boost Your Career with SAP Skills My Learning screenshot',\n",
        "                                    'Learn how to learn (Google)',\n",
        "                                    'Business Communication (Google)',\n",
        "                                    'Communicate your ideas through storytelling and design (Google)',\n",
        "                                    'Get started with Microsoft Teams',\n",
        "                                    'Tech for Good: The Role of ICT in Achieving the SDGs'\n",
        "                                    ]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3ca647c",
      "metadata": {
        "id": "f3ca647c"
      },
      "outputs": [],
      "source": [
        "# Check the data types of each column\n",
        "df_learners_selected.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46aad4e3",
      "metadata": {
        "id": "46aad4e3"
      },
      "outputs": [],
      "source": [
        "# How many learners have started / made progress?\n",
        "\n",
        "df_learners_selected['Block 1 progress %'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62d8185",
      "metadata": {
        "id": "f62d8185"
      },
      "outputs": [],
      "source": [
        "# Filter the DataFrame to include only learners who have started\n",
        "df_learners_selected = df_learners_selected[df_learners_selected['Block 1 progress %'] >= 0.1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61e6f88",
      "metadata": {
        "id": "d61e6f88"
      },
      "outputs": [],
      "source": [
        "# Check the DataFrame has been filtered\n",
        "df_learners_selected.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c2e18a",
      "metadata": {
        "id": "30c2e18a"
      },
      "outputs": [],
      "source": [
        "# Check for missing values - incomplete courses\n",
        "df_learners_selected.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6170295a",
      "metadata": {
        "id": "6170295a"
      },
      "outputs": [],
      "source": [
        "df_learners_selected.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690aac6c",
      "metadata": {
        "id": "690aac6c"
      },
      "outputs": [],
      "source": [
        "# Extract file names of the certificate images uploaded by learners\n",
        "\n",
        "columns_to_process = certificate_names\n",
        "\n",
        "for col in columns_to_process:\n",
        "    for idx, data_str in df_learners_selected[col].items():\n",
        "        if isinstance(data_str, str):  # Skip if not a string\n",
        "            try:\n",
        "                data = literal_eval(data_str)\n",
        "                filenames = []\n",
        "                for entry in data:\n",
        "                    if 'filename' in entry:\n",
        "                        filenames.append(entry['filename'])\n",
        "                if filenames:\n",
        "                    df_learners_selected.at[idx, col] = filenames\n",
        "            except (ValueError, SyntaxError):  # Catching errors related to literal_eval\n",
        "                print(f\"Could not decode: {data_str} in column {col}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fafb0b65",
      "metadata": {
        "id": "fafb0b65"
      },
      "outputs": [],
      "source": [
        "# Confirm file names have been extracted in lists\n",
        "df_learners_selected.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b582831c",
      "metadata": {
        "id": "b582831c"
      },
      "outputs": [],
      "source": [
        "df_learners_selected.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7eba990",
      "metadata": {
        "id": "f7eba990"
      },
      "outputs": [],
      "source": [
        "# Find a specific file\n",
        "\n",
        "# Assuming df_learners_selected is your DataFrame and 'column_name' is the name of the column you want to search in\n",
        "matched_rows = df_learners_selected.loc[df_learners_selected['Boost Your Career with SAP Skills My Learning screenshot'] == 'Screenshot_20230913-233344_Chrome.jpg']\n",
        "\n",
        "# If you want to search in all columns, you can do:\n",
        "matched_rows = df_learners_selected[df_learners_selected.apply(lambda row: row.astype(str).str.contains('Screenshot_20230913-233344_Chrome.jpg').any(), axis=1)]\n",
        "\n",
        "# Now, matched_rows will contain all the rows where 'Screenshot_20230913-233344_Chrome.jpg' appears\n",
        "print(matched_rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f716fcca",
      "metadata": {
        "id": "f716fcca"
      },
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "\n",
        "def split_file_url_complex(entry):\n",
        "    '''\n",
        "    This function, split_file_url_complex, takes an entry from the \"Business Communication (Google)\" column\n",
        "    and separates it into multiple filenames and URLs. It uses regular expressions to find URLs and isolates\n",
        "    the filenames accordingly.\n",
        "\n",
        "    Parameters:\n",
        "        - entry (str): The original entry containing both filenames and URLs.\n",
        "\n",
        "    Returns:\n",
        "        - pd.Series: A pandas Series containing two lists, one for filenames and one for URLs.\n",
        "\n",
        "    Example:\n",
        "        Input: 'Screenshot.png (https://example.com/1), Image.jpg (https://example.com/2)'\n",
        "        Output: pd.Series([['Screenshot.png', 'Image.jpg'], ['https://example.com/1', 'https://example.com/2']])\n",
        "    '''\n",
        "\n",
        "    filenames = []\n",
        "    urls = []\n",
        "\n",
        "    if not isinstance(entry, str):\n",
        "        return pd.Series([filenames, urls])\n",
        "\n",
        "    # Use regex to find all URLs in the entry\n",
        "    found_urls = re.findall(r'https?://[^\\s,)]+', entry)\n",
        "    urls.extend(found_urls)\n",
        "\n",
        "    # Remove the found URLs from the original entry to isolate filenames\n",
        "    for url in found_urls:\n",
        "        entry = entry.replace(url, '')\n",
        "\n",
        "    # Split the remaining entry by comma to get filenames\n",
        "    filenames = entry.split(',')\n",
        "\n",
        "    # Strip extra spaces and parentheses from filenames\n",
        "    filenames = [name.replace('(', '').replace(')', '').strip() for name in filenames]\n",
        "\n",
        "    return pd.Series([filenames, urls])\n",
        "\n",
        "def download_file(url, file_path):\n",
        "    r = requests.get(url)\n",
        "    with open(file_path, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "\n",
        "def read_pdf_form_fields(file_path):\n",
        "    text_content = ''\n",
        "    pdf_reader = PdfReader(open(file_path, \"rb\"))\n",
        "    for i in range(len(pdf_reader.pages)):\n",
        "        page = pdf_reader.pages[i]\n",
        "\n",
        "        # Try to read form fields\n",
        "        if '/Annots' in page:\n",
        "            annotations = page['/Annots']\n",
        "            for annotation in annotations:\n",
        "                annotation_object = annotation.get_object()\n",
        "\n",
        "                # Look for form fields\n",
        "                if '/FT' in annotation_object and '/T' in annotation_object:\n",
        "                    field_name = annotation_object['/T']\n",
        "                    field_type = annotation_object['/FT']\n",
        "                    field_value = None\n",
        "\n",
        "                    if field_type == '/Tx':\n",
        "                        field_value = annotation_object.get('/V', None)\n",
        "\n",
        "                    text_content += f\"\\n{field_name}: {field_value}\"\n",
        "    return text_content.strip()\n",
        "\n",
        "def extract_text_from_file(file_path):\n",
        "    file_extension = os.path.splitext(file_path)[-1].lower()\n",
        "\n",
        "    def image_to_text(image_path):\n",
        "        try:\n",
        "            # Try using OpenCV first\n",
        "            print(\"Attempting to read with OpenCV\")\n",
        "            image = cv2.imread(image_path)\n",
        "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            pil_image = Image.fromarray(gray_image)\n",
        "            return pytesseract.image_to_string(pil_image, config='--psm 6').strip()\n",
        "        except Exception as e1:\n",
        "            print(f\"Failed to process {image_path} with OpenCV: {str(e1)}\")\n",
        "\n",
        "            # Try using PIL as a fallback\n",
        "            try:\n",
        "                print(\"Attempting to read with PIL\")\n",
        "                image = Image.open(image_path)\n",
        "                return pytesseract.image_to_string(image).strip()\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred with PIL while processing {image_path}: {str(e)}\")\n",
        "                return \"\"\n",
        "\n",
        "    try:\n",
        "        if file_extension == '.pdf':\n",
        "            text_content_plumber = ''\n",
        "\n",
        "            # First, use pdfplumber\n",
        "            with pdfplumber.open(file_path) as pdf:\n",
        "                for page in pdf.pages:\n",
        "                    text_content_plumber += page.extract_text()\n",
        "\n",
        "            # Combine and keep unique lines (assuming you have a function read_pdf_form_fields)\n",
        "            text_content_reader = read_pdf_form_fields(file_path)\n",
        "            combined_text = set(text_content_plumber.splitlines()) | set(text_content_reader.splitlines())\n",
        "            combined_text_str = \"\\n\".join(combined_text)\n",
        "\n",
        "            return combined_text_str.strip()\n",
        "\n",
        "        elif file_extension in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']:\n",
        "            try:\n",
        "                return image_to_text(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while processing {file_path}: {str(e)}\")\n",
        "                return convert_image_and_process(file_path, image_to_text)\n",
        "\n",
        "        else:\n",
        "            return \"\"  # Unsupported file format\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {file_path}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "# Test extract_text_from_file(file_path)\n",
        "text = extract_text_from_file(\"/Users/gilbert/Downloads/content/attachments/Boost Your Career with SAP Skills My Learning screenshot/Screenshot_20230913-233344_Chrome.jpg\")\n",
        "print(text)\n",
        "\n",
        "def convert_image_and_process(file_path, processing_function):\n",
        "    try:\n",
        "        file_extension = os.path.splitext(file_path)[-1].lower()\n",
        "\n",
        "        # If the file is already a PNG, convert to JPG, otherwise convert to PNG\n",
        "        new_extension = '.jpg' if file_extension == '.png' else '.png'\n",
        "\n",
        "        print(f\"Attempting to convert {file_path} to {new_extension} and process again.\")\n",
        "\n",
        "        converted_file_path = file_path.replace(file_extension, new_extension)\n",
        "        image = Image.open(file_path)\n",
        "        image.save(converted_file_path)\n",
        "\n",
        "        return processing_function(converted_file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {file_path} even after converting to {new_extension}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def convert_file_to_images(file_path):\n",
        "    file_extension = os.path.splitext(file_path)[-1].lower()\n",
        "\n",
        "    if file_extension not in SUPPORTED_EXTENSIONS:\n",
        "        raise Exception(f\"Unsupported file format: {file_extension}. Manual handling required.\")\n",
        "\n",
        "    images = []\n",
        "\n",
        "    if file_extension == '.pdf':\n",
        "        images = convert_from_path(file_path)\n",
        "    else:\n",
        "        try:\n",
        "            # Try reading with OpenCV first\n",
        "            print(\"Attempting to read with OpenCV\")\n",
        "            img = cv2.imread(file_path)\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            pil_img = Image.fromarray(img_rgb)\n",
        "            images.append(pil_img)\n",
        "        except Exception as cv_error:\n",
        "            print(f\"OpenCV failed to process {file_path}: {cv_error}\")\n",
        "\n",
        "            try:\n",
        "                # Fallback to PIL\n",
        "                images.append(Image.open(file_path))\n",
        "                print(\"Attempting to read with PIL\")\n",
        "            except Exception as pil_error:\n",
        "                print(f\"An error occurred with PIL while processing {file_path}: {pil_error}\")\n",
        "\n",
        "    return images\n",
        "\n",
        "def compare_images(img1, img2):\n",
        "    img1_gray = cv2.cvtColor(np.array(img1), cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(np.array(img2), cv2.COLOR_BGR2GRAY)\n",
        "# Resize the image if they are not of the same shape\n",
        "    if img1_gray.shape != img2_gray.shape:\n",
        "        img2_gray = cv2.resize(img2_gray, (img1_gray.shape[1], img1_gray.shape[0]))\n",
        "\n",
        "    return ssim(img1_gray, img2_gray)\n",
        "\n",
        "def resize_image(image, scale_percent=50):\n",
        "    width = int(image.shape[1] * scale_percent / 100)\n",
        "    height = int(image.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "    return cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "def evaluate_file_similarity(example_file_path, learner_file_path):\n",
        "    # Extract text (Optional, since we are focusing on visual analysis)\n",
        "    example_file_text = extract_text_from_file(example_file_path)\n",
        "    learner_file_text = extract_text_from_file(learner_file_path)\n",
        "\n",
        "    # Convert files to images\n",
        "    example_file_images = convert_file_to_images(example_file_path)\n",
        "    learner_file_images = convert_file_to_images(learner_file_path)\n",
        "\n",
        "    # Assume the first page/image is the most relevant for comparison\n",
        "    example_image_np = np.array(example_file_images[0])\n",
        "    learner_image_np = np.array(learner_file_images[0])\n",
        "\n",
        "    # Resize the images\n",
        "    example_image_resized = resize_image(example_image_np)\n",
        "    learner_image_resized = resize_image(learner_image_np)\n",
        "\n",
        "    # Compare the resized images\n",
        "    similarity_index_resized = compare_images(example_image_resized, learner_image_resized)\n",
        "\n",
        "    return similarity_index_resized\n",
        "\n",
        "def evaluate_batch_similarity(example_file_path, learner_file_paths):\n",
        "    # Store the results here\n",
        "    batch_results = {}\n",
        "\n",
        "    # Convert the example certificate to images\n",
        "    example_file_images = convert_file_to_images(example_file_path)\n",
        "    example_image_np = np.array(example_file_images[0])\n",
        "    example_image_resized = resize_image(example_image_np)\n",
        "\n",
        "    for learner_file_path in learner_file_paths:\n",
        "        # Convert learner files to images\n",
        "        learner_file_images = convert_file_to_images(learner_file_path)\n",
        "        learner_image_np = np.array(learner_file_images[0])\n",
        "        learner_image_resized = resize_image(learner_image_np)\n",
        "\n",
        "        # Compare the resized images\n",
        "        similarity_index_resized = compare_images(example_image_resized, learner_image_resized)\n",
        "\n",
        "        # Store the result\n",
        "        batch_results[learner_file_path] = similarity_index_resized\n",
        "\n",
        "    return batch_results\n",
        "\n",
        "def calculate_text_similarity(reference_text, comparison_text):\n",
        "    if not comparison_text:\n",
        "        return 0\n",
        "    return fuzz.ratio(reference_text, comparison_text)\n",
        "\n",
        "def calculate_text_similarity_key_phrases(reference_key_phrases, comparison_text):\n",
        "    if not comparison_text:\n",
        "        return 0\n",
        "\n",
        "    score = 0\n",
        "    for phrase in reference_key_phrases:\n",
        "        if phrase.lower() in comparison_text.lower():  # Case insensitive check\n",
        "            score += 1\n",
        "\n",
        "    # Normalize by the total number of key phrases to get a similarity score between 0 and 100\n",
        "    normalized_score = (score / len(reference_key_phrases)) * 100\n",
        "\n",
        "    return normalized_score\n",
        "\n",
        "def calculate_learner_id_similarity(comparison_text, learner_id):\n",
        "    # Tokenize both strings into words\n",
        "    comparison_words = set(comparison_text.lower().split())\n",
        "    learner_id_words = set(learner_id.lower().split())\n",
        "\n",
        "    # Calculate intersection and union of both sets\n",
        "    intersection = len(comparison_words & learner_id_words)\n",
        "    union = len(comparison_words | learner_id_words)\n",
        "\n",
        "    # If union is zero, return 0% similarity\n",
        "    if union == 0:\n",
        "        return 0\n",
        "\n",
        "    # Calculate Jaccard similarity and multiply by 100 for percentage\n",
        "    similarity = (intersection / union) * 100\n",
        "\n",
        "    return round(similarity, 2)  # Round to two decimal places"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccea9c4a",
      "metadata": {
        "id": "ccea9c4a"
      },
      "outputs": [],
      "source": [
        "# This function takes a string cert_data_str which can be either a list-like object or a JSON-like string. It processes it to return a list.\n",
        "\n",
        "def process_cert_data(cert_data_str):\n",
        "    if isinstance(cert_data_str, list):\n",
        "        if not cert_data_str:  # Skip if the list is empty\n",
        "            return []\n",
        "        return cert_data_str  # It's already a list\n",
        "    else:\n",
        "        if pd.isna(cert_data_str) or not cert_data_str:  # Check if it's NaN or an empty string\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            # Parsing the string into a list of dictionaries\n",
        "            return json.loads(cert_data_str.replace(\"'\", '\"'))\n",
        "        except json.JSONDecodeError:\n",
        "            return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5381db66",
      "metadata": {
        "id": "5381db66"
      },
      "outputs": [],
      "source": [
        "# This function looks into cache_df DataFrame to find if a cached similarity exists for a given cache_key. If it does, it returns those values; otherwise, it calculates new ones and updates the cache.\n",
        "\n",
        "def fetch_cached_similarity(cache_df, cache_key, example_cert_path, file_path, learner_id):\n",
        "    cached_row = cache_df[cache_df['Cache Key'] == cache_key]\n",
        "\n",
        "    if cached_row.empty:\n",
        "        # Assuming functions evaluate_file_similarity, calculate_text_similarity,\n",
        "        # and calculate_learner_id_similarity are defined elsewhere\n",
        "        visual_similarity = evaluate_file_similarity(example_cert_path, file_path)\n",
        "        text_similarity = calculate_text_similarity(example_cert_path, file_path)\n",
        "        learner_id_similarity = calculate_learner_id_similarity(learner_id, file_path)\n",
        "\n",
        "        new_cache_row = pd.DataFrame({\n",
        "            'Cache Key': [cache_key],\n",
        "            'Visual Similarity': [visual_similarity],\n",
        "            'Text Similarity': [text_similarity],\n",
        "            'Learner ID Similarity': [learner_id_similarity]\n",
        "        })\n",
        "\n",
        "        # Check for NA entries before concatenating\n",
        "        if new_cache_row.dropna().empty:\n",
        "            print(\"new_cache_row contains only NA entries; skipping concatenation.\")\n",
        "        else:\n",
        "            cache_df = pd.concat([cache_df, new_cache_row], ignore_index=True)\n",
        "\n",
        "        return visual_similarity, text_similarity, learner_id_similarity, cache_df\n",
        "    else:\n",
        "        visual_similarity = cached_row['Visual Similarity'].iloc[0]\n",
        "        text_similarity = cached_row['Text Similarity'].iloc[0]\n",
        "        learner_id_similarity = cached_row['Learner ID Similarity'].iloc[0]\n",
        "\n",
        "        return visual_similarity, text_similarity, learner_id_similarity, cache_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bcb91b9",
      "metadata": {
        "id": "2bcb91b9"
      },
      "outputs": [],
      "source": [
        "# Clean file paths\n",
        "def sanitize_path(file_path):\n",
        "    return os.path.normpath(file_path.replace(\"\\\\\", \"/\"))\n",
        "\n",
        "# Check file paths exist\n",
        "def check_file_exists(file_path):\n",
        "    return os.path.exists(file_path)\n",
        "\n",
        "# Log Errors with extra info\n",
        "def log_error(learner_id, certificate_column, file_name, error_msg, extra_info=None):\n",
        "    new_row = pd.DataFrame({\n",
        "        'Learner ID': [learner_id],\n",
        "        'Certificate Type': [certificate_column],\n",
        "        'File Name': [file_name],\n",
        "        'Status': ['Failure'],\n",
        "        'Highest Visual Similarity': [None],\n",
        "        'Text Similarity Score': [None],\n",
        "        'Learner ID Similarity Score': [None],\n",
        "        'Errors': [error_msg],\n",
        "        'Extra Info': [extra_info]  # Add this line\n",
        "    })\n",
        "    return new_row\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4782ea4f",
      "metadata": {
        "id": "4782ea4f"
      },
      "outputs": [],
      "source": [
        "# Function to save log DataFrame to CSV\n",
        "def save_log_to_csv(df, path):\n",
        "    df.to_csv(path, index=False)\n",
        "\n",
        "# Function to load log DataFrame from CSV\n",
        "def load_log_from_csv(path):\n",
        "    if os.path.exists(path):\n",
        "        return pd.read_csv(path)\n",
        "    else:\n",
        "        return pd.DataFrame(columns=['Learner ID', 'Certificate Type', 'File Name', 'Status', 'Highest Visual Similarity', 'Text Similarity Score', 'Learner ID Similarity Score', 'Errors', 'Extra Info'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd941b92",
      "metadata": {
        "id": "dd941b92"
      },
      "outputs": [],
      "source": [
        "# Main Loop to evaluate the learners uploaded images against the example certificates\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Load existing log_df from CSV if it exists\n",
        "    log_csv_path = '/Users/gilbert/Downloads/log_df.csv'\n",
        "    log_df = load_log_from_csv(log_csv_path)\n",
        "\n",
        "    processed_entries = set(log_df.apply(lambda row: (row['Learner ID'], row['Certificate Type'], row['File Name']), axis=1))\n",
        "\n",
        "    row_limit = 10000  # Define the row limit for testing\n",
        "\n",
        "    row_counter = 0  # Initialize a counter\n",
        "\n",
        "    columns_to_process = certificate_names  # Columns to process\n",
        "\n",
        "    for idx, row in df_learners_selected.iterrows():\n",
        "\n",
        "        if row_counter >= row_limit:\n",
        "            print(f\"Reached row limit of {row_limit}. Stopping processing.\")\n",
        "            break\n",
        "\n",
        "        learner_id = row['Learner ID']\n",
        "\n",
        "        log_rows = []  # Initialize an empty list to collect new log rows for this learner\n",
        "\n",
        "        for certificate_column in columns_to_process:\n",
        "\n",
        "            cert_data_list = row[certificate_column]\n",
        "\n",
        "            if not isinstance(cert_data_list, list):\n",
        "                continue\n",
        "\n",
        "            for file_name in cert_data_list:\n",
        "\n",
        "                entry = (learner_id, certificate_column, file_name)\n",
        "\n",
        "                if entry in processed_entries:\n",
        "                    print(f\"Skipping already processed entry: {entry}\")\n",
        "                    continue\n",
        "\n",
        "                file_path = os.path.join(attachments_dir, certificate_column, file_name)\n",
        "                file_path = sanitize_path(file_path)  # Sanitize the path\n",
        "\n",
        "                if not check_file_exists(file_path):  # Check if file exists\n",
        "                    new_row = log_error(learner_id, certificate_column, file_name, f\"File not found: {file_path}\").iloc[0].to_dict()\n",
        "                    log_rows.append(new_row)\n",
        "                    continue  # Skip this file and move to the next\n",
        "\n",
        "                example_cert_paths = cert_name_to_example_paths.get(certificate_column, [])\n",
        "\n",
        "                for example_cert_path in example_cert_paths:\n",
        "\n",
        "                    try:\n",
        "                        cache_key = f\"{file_path}-{example_cert_path}\"\n",
        "                        visual_similarity, text_similarity, learner_id_similarity, cache_df = fetch_cached_similarity(\n",
        "                            cache_df, cache_key, example_cert_path, file_path, learner_id)\n",
        "\n",
        "                        new_row = {\n",
        "                            'Learner ID': learner_id,\n",
        "                            'Certificate Type': certificate_column,\n",
        "                            'File Name': file_name,\n",
        "                            'Status': 'Success',\n",
        "                            'Highest Visual Similarity': visual_similarity,\n",
        "                            'Text Similarity Score': text_similarity,\n",
        "                            'Learner ID Similarity Score': learner_id_similarity,\n",
        "                            'Errors': None  # No errors, so None\n",
        "                        }\n",
        "                        log_rows.append(new_row)\n",
        "\n",
        "                    except FileNotFoundError:\n",
        "                        error_msg = f\"File not found: {file_path} or {example_cert_path}\"\n",
        "                        extra_info = f\"Current working directory: {os.getcwd()}, File Size: {os.path.getsize(file_path) if os.path.exists(file_path) else 'N/A'}\"\n",
        "                        new_row = log_error(learner_id, certificate_column, file_name, error_msg, extra_info).iloc[0].to_dict()\n",
        "                        log_rows.append(new_row)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        error_msg = f\"An exception occurred: {e}\"\n",
        "                        extra_info = f\"Exception type: {type(e).__name__}, Arguments: {e.args}\"\n",
        "                        new_row = log_error(learner_id, certificate_column, file_name, error_msg, extra_info).iloc[0].to_dict()\n",
        "                        log_rows.append(new_row)\n",
        "\n",
        "                # Increment the counter at the end of processing each row\n",
        "                row_counter += 1\n",
        "\n",
        "        # Save log_df to CSV after each learner is processed\n",
        "        log_df = pd.concat([log_df, pd.DataFrame(log_rows)], ignore_index=True)\n",
        "        save_log_to_csv(log_df, log_csv_path)\n",
        "\n",
        "        # Add the processed learner to the set\n",
        "        processed_entries.add(entry)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef3bb49",
      "metadata": {
        "id": "9ef3bb49"
      },
      "outputs": [],
      "source": [
        "log_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e7ba127",
      "metadata": {
        "id": "9e7ba127"
      },
      "outputs": [],
      "source": [
        "log_df['Learner ID Similarity Score'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0808c72b",
      "metadata": {
        "id": "0808c72b"
      },
      "outputs": [],
      "source": [
        "log_df[log_df['Learner ID Similarity Score']>0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1217fbe",
      "metadata": {
        "id": "d1217fbe"
      },
      "outputs": [],
      "source": [
        "log_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58e8cc3e",
      "metadata": {
        "id": "58e8cc3e"
      },
      "outputs": [],
      "source": [
        "# Save log_df as csv\n",
        "log_df.to_csv('/Users/gilbert/Downloads/log_df_backup2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5e1803e",
      "metadata": {
        "id": "d5e1803e"
      },
      "outputs": [],
      "source": [
        "# Upload log_df if you want to use a saved copy. Usually you would generate it in the Main Function.\n",
        "# log_df = pd.read_csv('/Users/gilbert/Downloads/log_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fe7b76d",
      "metadata": {
        "id": "6fe7b76d"
      },
      "outputs": [],
      "source": [
        "log_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ae1a82",
      "metadata": {
        "id": "66ae1a82"
      },
      "outputs": [],
      "source": [
        "log_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61091a65",
      "metadata": {
        "id": "61091a65"
      },
      "outputs": [],
      "source": [
        "# Set the display option to avoid truncation of text in the Errors column\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Now print the 'Errors' column\n",
        "log_df[log_df['Errors'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a6b258",
      "metadata": {
        "id": "a1a6b258"
      },
      "outputs": [],
      "source": [
        "# Copy the error files for inspection - FILES COPIED SEEM FINE? I think there an error in Errors logging\n",
        "\n",
        "# Create error directory if it doesn't exist\n",
        "error_dir = os.path.join(attachments_dir, 'errors')\n",
        "if not os.path.exists(error_dir):\n",
        "    os.makedirs(error_dir)\n",
        "\n",
        "# Copy files that produced errors\n",
        "for idx, row in log_df[log_df['Errors'].notna()].iterrows():\n",
        "    src_path = os.path.join(attachments_dir, row['Certificate Type'], row['File Name'])\n",
        "    dest_file_name = f\"{row['Learner ID']} - {row['Certificate Type']} - {row['File Name']}\"\n",
        "    dest_path = os.path.join(error_dir, dest_file_name)\n",
        "\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.copy(src_path, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53db4385",
      "metadata": {
        "id": "53db4385"
      },
      "outputs": [],
      "source": [
        "# Convert 'Text Similarity Score' to numeric, setting errors='coerce' will turn unconvertible values to NaN\n",
        "log_df['Text Similarity Score'] = pd.to_numeric(log_df['Text Similarity Score'], errors='coerce')\n",
        "\n",
        "# Convert 'Learner ID Similarity Score' to numeric, setting errors='coerce' will turn unconvertible values to NaN\n",
        "log_df['Learner ID Similarity Score'] = pd.to_numeric(log_df['Learner ID Similarity Score'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22db4be5",
      "metadata": {
        "id": "22db4be5"
      },
      "outputs": [],
      "source": [
        "log_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d45bb1",
      "metadata": {
        "id": "c6d45bb1"
      },
      "outputs": [],
      "source": [
        "log_df['Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49afa886",
      "metadata": {
        "id": "49afa886"
      },
      "outputs": [],
      "source": [
        "# Check scores\n",
        "\n",
        "# Columns to analyze\n",
        "columns_to_analyze = ['Highest Visual Similarity', 'Text Similarity Score', 'Learner ID Similarity Score']\n",
        "\n",
        "for col in columns_to_analyze:\n",
        "    filled_df = log_df.fillna({col: 0})\n",
        "    global_min = filled_df[col].min()\n",
        "    global_max = filled_df[col].max()\n",
        "\n",
        "    # Create the grid of subplots\n",
        "    g = sns.FacetGrid(log_df, col='Certificate Type', col_wrap=3, height=4, aspect=1.2)\n",
        "    g = (g.map(plt.hist, col, bins=20, edgecolor='black', range=[global_min, global_max])\n",
        "         .set_axis_labels(col, 'Frequency')\n",
        "         .set_titles(\"Certificate Type: {col_name}\"))\n",
        "\n",
        "    # Adjust layout for better spacing\n",
        "    g.fig.subplots_adjust(top=0.9, bottom=0.1, wspace=0.2, hspace=0.4)\n",
        "    g.fig.suptitle(f'{col} by Certificate Type', fontsize=16)\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b937b563",
      "metadata": {
        "id": "b937b563"
      },
      "outputs": [],
      "source": [
        "log_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37342ec9",
      "metadata": {
        "id": "37342ec9"
      },
      "outputs": [],
      "source": [
        "log_df[['Highest Visual Similarity', 'Text Similarity Score', 'Learner ID Similarity Score']].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d0831b",
      "metadata": {
        "id": "65d0831b"
      },
      "outputs": [],
      "source": [
        "log_df[log_df['Status'] != 'Success']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0242476c",
      "metadata": {
        "id": "0242476c"
      },
      "outputs": [],
      "source": [
        "log_df[log_df['Status'] != 'Success']['Errors'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a680d20",
      "metadata": {
        "id": "5a680d20"
      },
      "outputs": [],
      "source": [
        "log_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d4e58f3",
      "metadata": {
        "id": "8d4e58f3"
      },
      "outputs": [],
      "source": [
        "# Pivot data\n",
        "\n",
        "# Group by 'Learner ID' and 'Certificate Type' and take the max value for each group\n",
        "grouped_df = log_df[['Learner ID', 'Certificate Type', 'Highest Visual Similarity', 'Text Similarity Score', 'Learner ID Similarity Score']].groupby(['Learner ID', 'Certificate Type']).max().reset_index()\n",
        "\n",
        "# Reshape the DataFrame\n",
        "pivot_df = pd.pivot_table(grouped_df, index='Learner ID', columns='Certificate Type',\n",
        "                          values=['Highest Visual Similarity', 'Text Similarity Score', 'Learner ID Similarity Score'],\n",
        "                          aggfunc='first')\n",
        "\n",
        "# Flatten the multi-level column names and add custom label\n",
        "pivot_df.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_df.columns.values]\n",
        "\n",
        "# Reset index\n",
        "pivot_df.reset_index(inplace=True)\n",
        "\n",
        "# Sort columns\n",
        "sorted_cols = ['Learner ID'] + sorted([col for col in pivot_df.columns if col != 'Learner ID'])\n",
        "pivot_df = pivot_df[sorted_cols]\n",
        "\n",
        "pivot_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b5fced",
      "metadata": {
        "id": "e0b5fced"
      },
      "outputs": [],
      "source": [
        "# Save to a CSV\n",
        "pivot_df.to_csv(\"pivot_backup2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c97be1d1",
      "metadata": {
        "id": "c97be1d1"
      },
      "outputs": [],
      "source": [
        "pivot_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e09efa8",
      "metadata": {
        "id": "0e09efa8"
      },
      "outputs": [],
      "source": [
        "pivot_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7c6260b",
      "metadata": {
        "id": "a7c6260b"
      },
      "outputs": [],
      "source": [
        "# Calculate thresholds for accepting / rejecting certificates\n",
        "\n",
        "# Initialize an empty DataFrame\n",
        "calculated_thresholds_df = pd.DataFrame(columns=['Certificate Type', 'Visual_Threshold_Percentile', 'Visual_Threshold_Zscore', 'Text_Threshold_Percentile', 'Text_Threshold_Zscore', 'Learner_ID_Threshold_Percentile', 'Learner_ID_Threshold_Zscore'])\n",
        "\n",
        "# Loop through each certificate type to calculate thresholds\n",
        "for cert_type in certificate_names:\n",
        "    visual_data = pivot_df[f\"{cert_type}_Highest Visual Similarity\"].dropna()\n",
        "    text_data = pivot_df[f\"{cert_type}_Text Similarity Score\"].dropna()\n",
        "    learner_id_data = pivot_df[f\"{cert_type}_Learner ID Similarity Score\"].dropna()\n",
        "\n",
        "    # Calculate Percentile\n",
        "    visual_threshold_percentile = visual_data.quantile(percentile_factor)\n",
        "    text_threshold_percentile = text_data.quantile(percentile_factor)\n",
        "    learner_id_threshold_percentile = learner_id_data.quantile(percentile_factor)\n",
        "\n",
        "    # Calculate Z-score thresholds\n",
        "    visual_threshold_zscore = visual_data.mean() + z_score_factor * visual_data.std()\n",
        "    text_threshold_zscore = text_data.mean() + z_score_factor * text_data.std()\n",
        "    learner_id_threshold_zscore = learner_id_data.mean() + z_score_factor * learner_id_data.std()\n",
        "\n",
        "    # Create a DataFrame for the current certificate type\n",
        "    temp_df = pd.DataFrame({\n",
        "        'Certificate Type': [cert_type],\n",
        "        'Visual_Threshold_Percentile': [visual_threshold_percentile],\n",
        "        'Visual_Threshold_Zscore': [visual_threshold_zscore],\n",
        "        'Text_Threshold_Percentile': [text_threshold_percentile],\n",
        "        'Text_Threshold_Zscore': [text_threshold_zscore],\n",
        "        'Learner_ID_Threshold_Percentile': [learner_id_threshold_percentile],\n",
        "        'Learner_ID_Threshold_Zscore': [learner_id_threshold_zscore]\n",
        "    })\n",
        "\n",
        "    # Concatenate to the existing DataFrame\n",
        "    calculated_thresholds_df = pd.concat([calculated_thresholds_df, temp_df], ignore_index=True)\n",
        "\n",
        "# Show the DataFrame with calculated thresholds\n",
        "calculated_thresholds_df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "526cbd09",
      "metadata": {
        "id": "526cbd09"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty dictionary to store dynamic thresholds\n",
        "thresholds = {}\n",
        "\n",
        "# Loop through the DataFrame to populate the thresholds dictionary\n",
        "for index, row in calculated_thresholds_df.iterrows():\n",
        "    cert_type = row['Certificate Type']\n",
        "\n",
        "    thresholds[cert_type] = {\n",
        "        'visual': row['Visual_Threshold_Percentile'],  # Replace with row['Visual_Threshold_Zscore'] if you want to use Z-score\n",
        "        'text': row['Text_Threshold_Percentile'],  # Replace with row['Text_Threshold_Zscore'] if you want to use Z-score\n",
        "        'learner_id': row['Learner_ID_Threshold_Percentile']  # Replace with row['Learner_ID_Threshold_Zscore'] if you want to use Z-score\n",
        "    }\n",
        "\n",
        "# Now the thresholds dictionary is dynamically populated based on calculated_thresholds_df\n",
        "thresholds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54d3a2b8",
      "metadata": {
        "id": "54d3a2b8"
      },
      "outputs": [],
      "source": [
        "# Manually input thresholds\n",
        "thresholds = {\n",
        "'Boost Your Career with SAP Skills My Learning screenshot': {'visual': 0.50,'text': 50.0,'learner_id': 0.0},\n",
        "'Learn how to learn (Google)': {'visual': 0.50,'text': 50.0,'learner_id': 0.0},\n",
        "'Business Communication (Google)': {'visual': 0.50,'text': 50.0,'learner_id': 0.0},\n",
        "'Communicate your ideas through storytelling and design (Google)': {'visual': 0.50,'text': 50.0, 'learner_id': 0.0},\n",
        "'Get started with Microsoft Teams': {'visual': 0.50,'text': 50.0,'learner_id': 0.0},\n",
        "'Tech for Good: The Role of ICT in Achieving the SDGs': {'visual': 0.45,'text': 50.0,'learner_id': 0.0}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da1c2923",
      "metadata": {
        "id": "da1c2923"
      },
      "outputs": [],
      "source": [
        "# Evaluate images based on thresholds\n",
        "\n",
        "# Create new columns based on certificate-specific thresholds and reasons for rejection\n",
        "for cert_type in thresholds.keys():\n",
        "    visual_threshold = thresholds[cert_type]['visual']\n",
        "    text_threshold = thresholds[cert_type]['text']\n",
        "    learner_id_threshold = thresholds[cert_type]['learner_id']\n",
        "\n",
        "    col_suffix = f\"{cert_type}_AcceptOrReject\"\n",
        "    reason_suffix = f\"{cert_type}_RejectionReasons\"\n",
        "\n",
        "    # Create a series with rejection reasons\n",
        "    def find_rejection_reasons(row):\n",
        "        reasons = []\n",
        "        if row.get(f\"{cert_type}_Highest Visual Similarity\", 0) < visual_threshold:\n",
        "            reasons.append('Visual')\n",
        "        if row.get(f\"{cert_type}_Text Similarity Score\", 0) < text_threshold:\n",
        "            reasons.append('Text')\n",
        "        if row.get(f\"{cert_type}_Learner ID Similarity Score\", 0) < learner_id_threshold:\n",
        "            reasons.append('ID')\n",
        "        return reasons\n",
        "\n",
        "    # Create the AcceptOrReject and RejectionReasons columns\n",
        "    pivot_df.loc[:, col_suffix] = (\n",
        "        (pivot_df.get(f\"{cert_type}_Highest Visual Similarity\", 0) >= visual_threshold) &\n",
        "        (pivot_df.get(f\"{cert_type}_Text Similarity Score\", 0) >= text_threshold) &\n",
        "        (pivot_df.get(f\"{cert_type}_Learner ID Similarity Score\", 0) >= learner_id_threshold)\n",
        "    ).astype(int)\n",
        "\n",
        "    pivot_df[reason_suffix] = pivot_df.apply(find_rejection_reasons, axis=1)\n",
        "\n",
        "# Initialize an empty list to store the new order of columns\n",
        "new_column_order = ['Learner ID']  # Start with 'Learner ID'\n",
        "\n",
        "# Loop through each certificate type and arrange the columns\n",
        "for cert_type in thresholds.keys():\n",
        "    new_column_order.extend([\n",
        "        f\"{cert_type}_Highest Visual Similarity\",\n",
        "        f\"{cert_type}_Text Similarity Score\",\n",
        "        f\"{cert_type}_Learner ID Similarity Score\",\n",
        "        f\"{cert_type}_AcceptOrReject\",\n",
        "        f\"{cert_type}_RejectionReasons\"  # Include the new RejectionReasons column\n",
        "    ])\n",
        "\n",
        "# Reorder the DataFrame columns based on the new list\n",
        "pivot_df = pivot_df[new_column_order]\n",
        "\n",
        "# Show the DataFrame with reordered columns\n",
        "pivot_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "455b96ef",
      "metadata": {
        "id": "455b96ef"
      },
      "outputs": [],
      "source": [
        "# Extract all columns that contain \"AcceptOrReject\"\n",
        "accept_or_reject_cols = [col for col in pivot_df.columns if \"AcceptOrReject\" in col]\n",
        "\n",
        "# Compute the minimum value along the rows for the AcceptOrReject columns\n",
        "minimums = pivot_df[accept_or_reject_cols].min(axis=1)\n",
        "\n",
        "# Create the 'Learner Status' column\n",
        "# If minimum is 0, set 'Learner Status' to 0, else set to 1\n",
        "pivot_df['Learner Status'] = (minimums != 0).astype(int)\n",
        "\n",
        "# View the updated DataFrame\n",
        "pivot_df[['Learner ID','Learner Status'] + accept_or_reject_cols]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d3b89d",
      "metadata": {
        "id": "b5d3b89d"
      },
      "outputs": [],
      "source": [
        "# Add an explanation by identifying which certificates were rejected\n",
        "\n",
        "# Extract all columns that contain \"AcceptOrReject\"\n",
        "accept_or_reject_cols = [col for col in pivot_df.columns if \"AcceptOrReject\" in col]\n",
        "\n",
        "# Compute the minimum value along the rows for the AcceptOrReject columns\n",
        "minimums = pivot_df[accept_or_reject_cols].min(axis=1)\n",
        "\n",
        "# Create the 'Learner Status' column\n",
        "# If minimum is 0, set 'Learner Status' to 0, else set to 1\n",
        "pivot_df['Learner Status'] = (minimums != 0).astype(int)\n",
        "\n",
        "# Create a new column to store the names of the AcceptOrReject columns that have 0 values\n",
        "def find_zero_cols(row):\n",
        "    zero_cols = [col.replace(\"_AcceptOrReject\", \"\") for col in accept_or_reject_cols if row[col] == 0]\n",
        "    return zero_cols  # Returning a list instead of a string\n",
        "\n",
        "pivot_df['Rejected Certificates'] = pivot_df.apply(find_zero_cols, axis=1)\n",
        "\n",
        "# View the updated DataFrame\n",
        "pivot_df[['Learner ID', 'Learner Status', 'Rejected Certificates'] + accept_or_reject_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a5cd45",
      "metadata": {
        "id": "b7a5cd45"
      },
      "outputs": [],
      "source": [
        "pivot_df[pivot_df['Learner Status']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00979440",
      "metadata": {
        "id": "00979440"
      },
      "outputs": [],
      "source": [
        "pivot_df[pivot_df['Learner Status']==0].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88ecd0b",
      "metadata": {
        "id": "c88ecd0b"
      },
      "outputs": [],
      "source": [
        "pivot_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ff906e",
      "metadata": {
        "id": "22ff906e"
      },
      "outputs": [],
      "source": [
        "# Merge pivot_df and df_learners_selected to compare scores with screenshots\n",
        "\n",
        "# Merge pivot_df and df_learners_selected based on 'Learner ID', keeping only the rows in pivot_df\n",
        "df_learners_evaluated = pd.merge(pivot_df, df_learners_selected, on='Learner ID', how='left')\n",
        "\n",
        "# Show the resulting DataFrame\n",
        "df_learners_evaluated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d259b210",
      "metadata": {
        "id": "d259b210"
      },
      "outputs": [],
      "source": [
        "df_learners_evaluated.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d8e808",
      "metadata": {
        "id": "68d8e808"
      },
      "outputs": [],
      "source": [
        "df_learners_evaluated.to_csv('/Users/gilbert/Downloads/learners_evaluated_2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "841833ca",
      "metadata": {
        "id": "841833ca"
      },
      "outputs": [],
      "source": [
        "# Inspect failed learners with histograms\n",
        "\n",
        "# Filter the DataFrame where 'Learner Status' equals 0\n",
        "filtered_df = df_learners_evaluated[\n",
        "    (df_learners_evaluated['Learner Status'] == 0) &\n",
        "    (df_learners_evaluated['Rejected Certificates'] == 'Tech for Good: The Role of ICT in Achieving the SDGs')\n",
        "]\n",
        "\n",
        "# Columns to create histograms for\n",
        "columns_to_plot = [\n",
        "    'Tech for Good: The Role of ICT in Achieving the SDGs_Highest Visual Similarity',\n",
        "    'Tech for Good: The Role of ICT in Achieving the SDGs_Text Similarity Score',\n",
        "    'Tech for Good: The Role of ICT in Achieving the SDGs_Learner ID Similarity Score'\n",
        "]\n",
        "\n",
        "# Create histograms\n",
        "for col in columns_to_plot:\n",
        "    sns.histplot(filtered_df[col], kde=False, bins=30)  # You can customize bins and other style options here\n",
        "    plt.title(f\"Histogram for {col}\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0a2698",
      "metadata": {
        "id": "fa0a2698"
      },
      "outputs": [],
      "source": [
        "print(df_learners_evaluated[df_learners_evaluated['Learner Status'] == 0]['Rejected Certificates'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4009207",
      "metadata": {
        "id": "d4009207"
      },
      "outputs": [],
      "source": [
        "df_learners_evaluated[(df_learners_evaluated['Learner Status'] == 0) & df_learners_evaluated['Rejected Certificates'].isna()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "009cf6b6",
      "metadata": {
        "id": "009cf6b6"
      },
      "outputs": [],
      "source": [
        "# Retrieve learner screenshots to inspect by cert type\n",
        "\n",
        "import math\n",
        "\n",
        "destination_base_folder = '/Users/gilbert/Downloads/check_temp'\n",
        "\n",
        "if not os.path.exists(destination_base_folder):\n",
        "    os.makedirs(destination_base_folder)\n",
        "\n",
        "for index, row in df_learners_evaluated.iterrows():\n",
        "    if row['Learner Status'] == 0:\n",
        "        learner_id = row['Learner ID']\n",
        "        rejected_certs = row['Rejected Certificates']\n",
        "\n",
        "        for cert_col in rejected_certs:\n",
        "            destination_folder = os.path.join(destination_base_folder, cert_col)\n",
        "            if not os.path.exists(destination_folder):\n",
        "                os.makedirs(destination_folder)\n",
        "\n",
        "            cert_names = row[cert_col]\n",
        "            if not isinstance(cert_names, list):\n",
        "                cert_names = [certificate_names]\n",
        "\n",
        "                print(f\"cert_names before loop: {cert_names}\")\n",
        "\n",
        "                for cert_name in cert_names:\n",
        "\n",
        "                    if cert_name is None or (isinstance(cert_name, float) and math.isnan(cert_name)):\n",
        "                        print(f\"Skipping invalid cert_name: {cert_name}\")\n",
        "                        continue\n",
        "\n",
        "                    source_folder = f\"/Users/gilbert/Downloads/content/attachments/{cert_col}\"\n",
        "                    source_file_path = os.path.join(source_folder, str(cert_name))  # Convert to str just in case\n",
        "\n",
        "                    print(f\"Checking existence of {source_file_path}\")  # Debug print\n",
        "\n",
        "                    if os.path.exists(source_file_path):\n",
        "                        file_extension = os.path.splitext(cert_name)[1]\n",
        "                        new_file_name = f\"{learner_id}{file_extension}\"\n",
        "                        destination_file_path = os.path.join(destination_folder, new_file_name)\n",
        "\n",
        "                        print(f\"Copying {source_file_path} to {destination_file_path}\")  # Debug print\n",
        "\n",
        "                        shutil.copy(source_file_path, destination_file_path)\n",
        "                    else:\n",
        "                        print(f\"File {source_file_path} does not exist.\")  # Debug print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa154e50",
      "metadata": {
        "id": "aa154e50"
      },
      "outputs": [],
      "source": [
        "# Retrieve learner screenshots to inspect - by learner\n",
        "destination_base_folder = '/Users/gilbert/Downloads/check_temp'\n",
        "\n",
        "if not os.path.exists(destination_base_folder):\n",
        "    os.makedirs(destination_base_folder)\n",
        "\n",
        "for index, row in df_learners_evaluated.iterrows():\n",
        "    if row['Learner Status'] == 0:\n",
        "        learner_id = row['Learner ID']\n",
        "        folder_name = learner_id\n",
        "\n",
        "        destination_folder = os.path.join(destination_base_folder, folder_name)\n",
        "        if not os.path.exists(destination_folder):\n",
        "            os.makedirs(destination_folder)\n",
        "\n",
        "        rejected_certs = row['Rejected Certificates']\n",
        "\n",
        "        for cert_col in rejected_certs:\n",
        "            cert_names = row[cert_col]\n",
        "            if not isinstance(cert_names, list):\n",
        "                cert_names = [cert_names]\n",
        "\n",
        "            for cert_name in cert_names:\n",
        "                source_folder = f\"/Users/gilbert/Downloads/content/attachments/{cert_col}\"\n",
        "                source_file_path = os.path.join(source_folder, cert_name)\n",
        "\n",
        "                print(f\"Checking existence of {source_file_path}\")  # Debug print\n",
        "\n",
        "                if os.path.exists(source_file_path):\n",
        "                    file_extension = os.path.splitext(cert_name)[1]\n",
        "                    new_file_name = f\"{cert_col}{file_extension}\"\n",
        "                    destination_file_path = os.path.join(destination_folder, new_file_name)\n",
        "\n",
        "                    print(f\"Copying {source_file_path} to {destination_file_path}\")  # Debug print\n",
        "\n",
        "                    shutil.copy(source_file_path, destination_file_path)\n",
        "                else:\n",
        "                    print(f\"File {source_file_path} does not exist.\")  # Debug print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94411967",
      "metadata": {
        "id": "94411967"
      },
      "outputs": [],
      "source": [
        "df_learners_evaluated.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c7bc4d3",
      "metadata": {
        "id": "5c7bc4d3"
      },
      "outputs": [],
      "source": [
        "# Inspect a learner\n",
        "\n",
        "# Select a specific learner based on 'Learner ID'\n",
        "specific_learner_df = df_learners_evaluated[df_learners_evaluated['Learner ID'] == 'Olawale  Raheem  - olawalehafees13@gmail.com']\n",
        "\n",
        "# Identify columns that end with '_RejectionReasons'\n",
        "rejection_reason_cols = [col for col in df_learners_evaluated.columns if col.endswith('_RejectionReasons')]\n",
        "\n",
        "# Create a list with 'Rejected Certificates' and all columns ending with '_RejectionReasons'\n",
        "columns_to_show = ['Rejected Certificates'] + rejection_reason_cols\n",
        "\n",
        "# Filter the DataFrame based on these columns\n",
        "filtered_learner_df = specific_learner_df[columns_to_show]\n",
        "\n",
        "# Display the result\n",
        "filtered_learner_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4333359",
      "metadata": {
        "id": "f4333359"
      },
      "outputs": [],
      "source": [
        "# Create a zip file from the folder\n",
        "shutil.make_archive('/content/check_temp', 'zip', '/content/check_temp')\n",
        "\n",
        "# Trigger the download\n",
        "files.download('/content/check_temp.zip')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}